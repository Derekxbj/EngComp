{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Content under Creative Commons Attribution license CC-BY 4.0, code under BSD 3-Clause License © 2017 L.A. Barba, N.C. Clementi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seeing stats in a new light\n",
    "\n",
    "Welcome to the second lesson in \"Take off with stats,\" Module 2 of our course in _Engineering Computations_. In the previous lesson, [Cheers! Stats with Beers](http://go.gwu.edu/engcomp2lesson1), we did some exploratory data analysis with a data set of canned craft beers in the US [1]. We'll continue using that same data set here, but with a new focus on _visualizing statistics_.\n",
    "\n",
    "In her lecture [\"Looking at Data\"](https://youtu.be/QYDuAo9r1xE), Prof. Kristin Sainani says that you should always plot your data. Immediatly, several things can come to light: are there outliers in your data? (Outliers are data points that look abnormally far from other values in the sample.) Are there data points that don't make sense? (Errors in data entry can be spotted this way.) And especially, you want to get a _visual_ representation of how data are distributed in your sample.\n",
    "\n",
    "In this lesson, we'll play around with different ways of visualizing data. There are so many ways to play! Have a look at the gallery of [The Data Viz Project](http://datavizproject.com) by ferdio (a data viz agency in Copenhagen). Aren't those gorgeous? Wouldn't you like to be able to make some pretty pics like that? Python can help!\n",
    "\n",
    "Let's begin. We'll import our favorite Python libraries, and set some font parameters for our plots to look nicer. Then we'll load our data set for craft beers and begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "#Import rcParams to set font styles\n",
    "from matplotlib import rcParams\n",
    "\n",
    "#Set font style and size \n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beers = pandas.read_csv(\"../../data/beers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note:\n",
    "\n",
    "If you downloaded this notebook alone, and don't have the data file on the location we assume above, get it by adding a code cell, and execute the following code in it:\n",
    "\n",
    "```Python\n",
    "from urllib.request import urlretrieve\n",
    "URL = 'http://go.gwu.edu/engcomp2data1?accessType=DOWNLOAD'\n",
    "urlretrieve(URL, 'beers.csv')\n",
    "```\n",
    "The data file will be downloaded to your working directory, and you will then need to remove the path information, i.e., the string `'../../data/'`, in the code to read it.\n",
    "\n",
    "OK. Let's have a look at the first few rows of the `pandas` dataframe we just created from the file, and confirm that it's a dataframe using the `type()` function. We only display the first 10 rows to save some space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(beers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beers[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical vs. quantitative data\n",
    "\n",
    "As you can see in the nice table that `pandas` printed for the dataframe, we have several features for each beer: the label `abv` corresponds to the acohol-by-volume fraction, label `ibu` refers to the international bitterness unit (IBU), then we have the `name` of the beer and the `style`, the brewery ID number, and the liquid volume of the beer can, in ounces.\n",
    "\n",
    "Alcohol-by-volume is a numeric feature: a volume fraction, with possible values from 0 to 1 (sometimes also given as a percentage). In the first 10 rows of our dataframe, the `ibu` value is missing (all those `NaN`s), but we saw in the previous lesson that `ibu` is also a numeric feature, with values that go from a minimum of 4 to a maximum of 138 (in our data set). IBU is pretty mysterious: how do you measure the bitterness of beer? It turns out that bitterness is measured as parts per million of _isohumulone_, the acid found in hops [2]. Who knew?\n",
    "\n",
    "For these numeric features, we learned that we can get an idea of the _central tendency_ in the data using the **mean value**, and we get ideas of _spread_ of the data with the **standard deviation** (and also with the range, but standard deviation is the most common).\n",
    "\n",
    "Notice that the beer data also has a feature named `style`: it can be \"American IPA\" or \"American Porter\" or a bunch of other styles of beer. If we want to study the beers according to style, we'll have to come up with some new ideas, because you can't take the mean or standard deviation of this feature!\n",
    "\n",
    "**Quantitative data** have meaning through a numeric feature, either on a continuous scale (like a fraction from 0 to 1), or a discrete count. \n",
    "**Categorical data**, in contrast, have meaning through a qualitative feature (like the style of beer). Data in this form can be collected in groups (categories), and then we can count the number of data items in that group. For example, we could ask how many beers (in our set) are of the style \"American IPA,\" or ask how many beers we have in each style.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing quantitative data\n",
    "\n",
    "In the previous lesson, we played around a bit with the `abv` and `ibu` columns of the dataframe `beers`. For each of these columns, we extracted it from the dataframe and saved it into a `pandas` series, then we used the `dropna()` method to get rid of null values. This \"clean\" data was our starting point for some exploratory data analysis, and for plotting the data distributions using **histograms**. Here, we will add a few more ingredients to our recipes for data exploration, and we'll learn about a new type of visualization: the **box plot**.\n",
    "\n",
    "Let's repeat here the process for extracting and cleaning the two series, and getting the values into NumPy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Repeat cleaning values abv\n",
    "abv_series = beers['abv']\n",
    "abv_clean = abv_series.dropna()\n",
    "abv = abv_clean.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Repeat cleaning values ibu\n",
    "ibu_series = beers['ibu']\n",
    "ibu_clean = ibu_series.dropna()\n",
    "ibu = ibu_clean.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also repeat a histogram plot for the `abv` variable, but this time choose to plot just 10 bins (you'll see why in a moment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(6,4))\n",
    "pyplot.hist(abv, bins=10, color='#3498db', histtype='bar', edgecolor='white') \n",
    "pyplot.title('Alcohol by Volume (abv) \\n')\n",
    "pyplot.xlabel('abv')\n",
    "pyplot.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can tell that the most frequent values of `abv` fall around 0.06, and below—0.06 happens to also be the mean value of our data, but data is not always so neat (sometimes, extreme values weigh heavily on the mean). Note also that we have a _right skewed_ distribution, meaning that more `abv` values occur in the lower end of the range than in the higher end.\n",
    "\n",
    "If you played around with the bin sizes in the previous lesson, you might have noticed that with a lot of bins, it becomes harder to visually pick out the patterns in the data. But if you use too few bins, the plot is also unhelpful. What number of bins is just right? Well, it depends on your data, so you'll just have to experiment and use your best judgement.\n",
    "\n",
    "Let's learn a new trick. It turns out that `pandas` has built-in methods to make histograms directly from columns of a dataframe! (It uses Matplotlib internally for that.) Check this out, and compare with our previous plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beers.hist(column='abv');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which one do you like better? Well, the `pandas` histogram was a lot less lines of code.  And it doesn't look bad at all. But we do have more fine-grained control with Matplotlib. Which method you choose in a real situation will just depend on the situation and your preference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring quantitative data (continued)\n",
    "\n",
    "In the previous lesson, you learned how to compute the mean of the data using `numpy.mean()`. How easy is that? But then we wrote our own custom functions to compute variance or standard deviation. It shouldn't surprise you by now that there are also NumPy functions for that!\n",
    "\n",
    "\n",
    "##### Exercise:\n",
    "\n",
    "Go to the documentation of [`numpy.var()`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.var.html) and analyze if this is the variance corresponding to the sample variance. \n",
    "\n",
    "*Hint*: Check what it says about the degrees of freedom.\n",
    "\n",
    "If you did the reading, you might have noticed that, by default, the argument `ddof` in `numpy.var()` is set to zero. If we use the default option, then we are not really calculating the sample variance. Recall from the previous lesson that the **sample variance** is:\n",
    "\n",
    "$$\n",
    "\\begin{equation*}     \n",
    "     var_{sample} = \\frac{1}{N-1}\\sum_{i} (x_i - \\bar{x})^2\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "Therefore, we need to be explicit about the division by $N-1$ when calling `numpy.var()`. How do we do that? We explicitly set `ddof` to `1`.  \n",
    "\n",
    "For example, to compute the sample variance for our `abv` variable we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_abv = numpy.var(abv, ddof=1)\n",
    "print(var_abv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the standard deviation by taking the square root of `var_abv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_abv = numpy.sqrt(var_abv)\n",
    "print(std_abv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might be wondering if there is a built-in function for the standard deviation in NumPy. Go on and search online and try to find something.\n",
    "\n",
    "**Spoiler alert!**\n",
    "You will. \n",
    "\n",
    "##### Exercise:\n",
    "\n",
    "1. Read the documentation about the NumPy standard deviation function, compute the standard deviation for `abv` using this function, and check that you obtained the same value than if you take the square root of the variance computed with NumPy.\n",
    "\n",
    "2. Compute the variance and standard deviation for the variable `ibu`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Median and percentiles\n",
    "\n",
    "So far, we've learned about the mean, variance and standard deviation of the data.\n",
    "\n",
    "We still haven't explored the concept of percentiles. The most well-known of these is the $50\\%$, also known as **median**. The **median** is the value that separates  in half. If the number of data values (sorted) is odd, the median is the middle value, otherwise, themedian is the average between the 2 values in the middle. \n",
    "\n",
    "If you went ahead, you probably already \"google\" if there is a NumPy function that computes the **median**, and you might have run into [`numpy.median()`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.median.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Exercise:\n",
    "\n",
    "Compute the median using NumPy, for our variables `abv` and `ibu`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Percentiles**\n",
    "\n",
    "A Percentile is a measurements that we use in statistics to indicate the value for which a vertain percentage of observations are lower. \n",
    "\n",
    "The Nth percentile is the value for which N% of the observations are lower. \n",
    "\n",
    "For example, imagine that you are the second tallest person in a group of 10 people. This mean that you are the 80th percentile. Let's say your height is 1.70 meters (~ 5' 7\"), this means that \"1.70 m\" is the 80th percentile. In other words, the height of 80% of the population (10 peeple) is under 1.70 m. \n",
    "\n",
    "The percentiles 25, 50, and 75 are named quartiles, since the divide the data into four groups. They are named first, second (median) and third quartile respectively. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.boxplot(abv, labels=['abv']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.boxplot(ibu, labels=['ibu']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing categorical data\n",
    "\n",
    "The typical method of visualizing categorical data is using _bar plots_. These show visually the frequency of appearance of items in each category, or the proportion of data in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "style_series = beers['style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(style_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_series[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_counts = style_series.value_counts()\n",
    "style_counts[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(style_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_counts[0:21].plot.barh(figsize=(10,8), color='#008367', edgecolor='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Bubble chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beers_clean = beers.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beers_styles = beers_clean.drop(['Unnamed: 0','name','brewery_id','ounces','id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beers_styles[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dataframe with only the numeric features `abv` and `ibu`, and the categorical feature `style`. We want to kow how many beers we have of each style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "style_counts = beers_styles['style'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_counts[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(style_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(style_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 90 different styles, and the number of beers in each style appears on each row of `style_counts`. According to our data, the most popular style is the _American IPA_, with 301 beers in the data set corresponding to this style.\n",
    "\n",
    "What would be a way to characterize the _style_ of the beers, given the data we have? Within a style, each beer has a different value of `abv` and `ibu`, but we can use the _mean value_ of each feature to characterize the style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "style_means = beers_styles.groupby('style').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_means[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_counts = style_counts.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_counts[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have available some plotting methods in `pandas` (which is actually calling Matplotlib internally). One of these is a scatter plot: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_means.plot.scatter(figsize=(10,10), \n",
    "                           x='abv', y='ibu', s=style_counts, \n",
    "                           alpha=0.3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "nrof_labels = len(style_counts)\n",
    "colors = cm.viridis(style_counts.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_means.plot.scatter(figsize=(10,10), \n",
    "                           x='abv', y='ibu', s=style_counts*15, color=colors,\n",
    "                           alpha=0.3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = style_means.plot.scatter(figsize=(12,12), \n",
    "                           x='abv', y='ibu', s=style_counts*15, color=colors,\n",
    "                           alpha=0.3);\n",
    "\n",
    "for i, txt in enumerate(list(style_counts.index.values)):\n",
    "    if style_counts.values[i] > 65:\n",
    "        ax.annotate(txt, (style_means.abv.iloc[i],style_means.ibu.iloc[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. [Craft beer datatset](https://github.com/nickhould/craft-beers-dataset) by Jean-Nicholas Hould.\n",
    "2. [What's The Meaning Of IBU?](https://beerconnoisseur.com/articles/whats-meaning-ibu) by Jim Dykstra for The Beer Connoisseur (2015).\n",
    "\n",
    "### Recommended viewing\n",
    "\n",
    "From [\"Statistics in Medicine,\"](https://lagunita.stanford.edu/courses/Medicine/MedStats-SP/SelfPaced/about), a free course in Stanford Online by Prof. Kristin Sainani, we highly recommend that you watch this lecture:\n",
    "* [Looking at data](https://youtu.be/QYDuAo9r1xE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell to load the notebook's style sheet, then ignore it\n",
    "from IPython.core.display import HTML\n",
    "css_file = '../../style/custom.css'\n",
    "HTML(open(css_file, \"r\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
